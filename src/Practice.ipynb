{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "\n",
    "from data_utils.load import beautiful_head, get_data, get_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = get_data()\n",
    "#test = pd.read_csv('../data/test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beautiful_head(train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check null value existance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace NaN values with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check one more time null value existance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehotencoding(data, features='all'):\n",
    "    \n",
    "    #import necessary modules\n",
    "    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    #write only categorical names to variable cat_columns\n",
    "    cat_columns_data = sorted([i for i in data.columns if data[i].dtype == 'O'])\n",
    "    \n",
    "    \n",
    "    if features == 'all':\n",
    "        features = cat_columns_data\n",
    "    else:\n",
    "        if type(features) != list:\n",
    "            raise ValueError(str(type(features)) + ' type passed in features. Only list are allowed.')\n",
    "        if len(features) == 0:\n",
    "            raise ValueError('You have chosen not enough features. The minimum number is one.')\n",
    "            \n",
    "        feat_not_in_data = [i for i in features if i not in cat_columns_data]\n",
    "        \n",
    "        if len(feat_not_in_data) > 0:\n",
    "            raise ValueError(','.join(feat_not_in_data) + ' are not in data.')\n",
    "            \n",
    "    #save all labels\n",
    "    labels = []\n",
    "    \n",
    "    # encode the first column\n",
    "    enc_label = LabelEncoder()\n",
    "    new_data = enc_label.fit_transform(data[features[0]])\n",
    "    labels.append(enc_label.classes_)\n",
    "    \n",
    "    # do the others\n",
    "    for i in features[1:]:\n",
    "        enc_label = LabelEncoder()\n",
    "        new_data = np.column_stack((new_data, enc_label.fit_transform(data[i])))\n",
    "        labels.append(enc_label.classes_)\n",
    "        \n",
    "    \n",
    "    #do OneHotEncoding\n",
    "    enc_onehot = OneHotEncoder()\n",
    "    new_data = enc_onehot.fit_transform(new_data)\n",
    "    \n",
    "    \n",
    "    # create a list of columns to help create a DF from np array \n",
    "    new_cols = [features[i] + '_' + str(j) for i in range(0,len(features)) for j in labels[i] ]\n",
    "    \n",
    "    # create new dataframe\n",
    "    new_data = pd.DataFrame(new_data.toarray(),columns=new_cols)\n",
    "    \n",
    "    for i in data.columns:\n",
    "        if i not in features:\n",
    "            new_data[i] = data[i]\n",
    "            \n",
    "            \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data for label encoding\n",
    "\n",
    "# first save target in a separate variable and drop index, id, codepostal\n",
    "# <YOUR CODE>\n",
    "\n",
    "# stack train and test sets for label encoding\n",
    "# <YOUR CODE>\n",
    "\n",
    "#find categorical variables for encoding\n",
    "# <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply ohe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# devide back new data frame on train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you should get train set shape is (300000, 266) and test set shape is (30000, 266)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing kfold for our cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metric mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply cv and train RandomForestRegressor model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run randomforest on the whole train set\n",
    "# <YOUR CODE>\n",
    "\n",
    "#make predictions\n",
    "# <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set params\n",
    "param = {}\n",
    "param['objective'] = 'reg:linear'\n",
    "param['max_depth'] = 5\n",
    "param['eta'] = .1\n",
    "param['colsample_bytree'] = .7\n",
    "param['subsample'] = .7\n",
    "param['nthread'] = 4\n",
    "param['silent'] = False\n",
    "plst = list(param.items()) #+ [('eval_metric', 'merror')]\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create mape metric for xgboost\n",
    "def xgb_mape(preds, df):\n",
    "    labels = df.get_label()\n",
    "    assert len(preds) == len(labels)\n",
    "    labels = np.array(labels)\n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    return 'error', mape(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply cv\n",
    "    \n",
    "    #initialize xgboost dmatrix\n",
    "    # <YOUR CODE>\n",
    "    \n",
    "    #train model\n",
    "    # <YOUR CODE>\n",
    "    \n",
    "    #make predictions and evaluate results\n",
    "    # <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run xbgoost on the whole train set\n",
    "# <YOUR CODE>\n",
    "\n",
    "# make predictions\n",
    "# <YOUR CODE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble randomForest & xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
